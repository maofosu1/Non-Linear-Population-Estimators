# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PqlMGLzOM8v10DZzb32zdz9HvnpuIjLf
"""

def generate_nonlinear_data(n_samples, n_features, noise=0.1):
    np.random.seed(0)
    X = np.random.rand(n_samples, n_features)
    true_beta = np.random.rand(n_features)
    Y = np.sin(X.dot(true_beta)) + noise * np.random.randn(n_samples)
    return X, Y, true_beta

# Generate data
n_samples = 1000
n_features = 3
X, Y, true_beta = generate_nonlinear_data(n_samples, n_features)

# Visualize the data
plt.figure(figsize=(10, 6))
plt.scatter(X[:, 0], Y, label='Data points')
plt.xlabel('Feature 1')
plt.ylabel('Target')
plt.title('Generated Nonlinear Data')
plt.legend()
plt.show()



import numpy as np
import matplotlib.pyplot as plt

# Simulate data
np.random.seed(42)
true_params = np.array([1.5, -2.0, 1.0])
x_data = np.linspace(0, 10, 100)
y_data = true_params[0] * np.sin(true_params[1] * x_data) + true_params[2] + np.random.normal(0, 0.5, len(x_data))

# Function to compute RMSE
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

# Function to generate different sample sizes
def generate_sample_sizes(x, y, sizes):
    sample_data = []
    for size in sizes:
        indices = np.random.choice(len(x), size, replace=False)
        sample_data.append((x[indices], y[indices]))
    return sample_data

# Sample sizes to test
sample_sizes = np.arange(10, 101, 10)

# Generate data for different sample sizes
sample_data = generate_sample_sizes(x_data, y_data, sample_sizes)

# Placeholder for RMSE values
rmse_fixed_point = []
rmse_newton_raphson = []
rmse_levenberg_marquardt = []

# Initial parameter guess
initial_params = np.array([1.0, -1.0, 0.5])

# Fixed-Point Iteration
for x_sample, y_sample in sample_data:
    params = initial_params.copy()
    for i in range(100):
        y_pred = params[0] * np.sin(params[1] * x_sample) + params[2]
        error = y_sample - y_pred
        params += 0.01 * np.array([np.sum(error * np.sin(params[1] * x_sample)),
                                   np.sum(error * params[0] * x_sample * np.cos(params[1] * x_sample)),
                                   np.sum(error)])
    y_pred_full = params[0] * np.sin(params[1] * x_data) + params[2]
    rmse_fixed_point.append(rmse(y_data, y_pred_full))

# Newton-Raphson
for x_sample, y_sample in sample_data:
    params = initial_params.copy()
    for i in range(10):
        y_pred = params[0] * np.sin(params[1] * x_sample) + params[2]
        error = y_sample - y_pred
        J = np.vstack((np.sin(params[1] * x_sample),
                       params[0] * x_sample * np.cos(params[1] * x_sample),
                       np.ones_like(x_sample))).T
        H = J.T @ J
        params += np.linalg.inv(H) @ J.T @ error
    y_pred_full = params[0] * np.sin(params[1] * x_data) + params[2]
    rmse_newton_raphson.append(rmse(y_data, y_pred_full))

# Levenberg-Marquardt
for x_sample, y_sample in sample_data:
    params = initial_params.copy()
    lambda_param = 0.01
    for i in range(10):
        y_pred = params[0] * np.sin(params[1] * x_sample) + params[2]
        error = y_sample - y_pred
        J = np.vstack((np.sin(params[1] * x_sample),
                       params[0] * x_sample * np.cos(params[1] * x_sample),
                       np.ones_like(x_sample))).T
        H = J.T @ J
        params += np.linalg.inv(H + lambda_param * np.eye(3)) @ J.T @ error
    y_pred_full = params[0] * np.sin(params[1] * x_data) + params[2]
    rmse_levenberg_marquardt.append(rmse(y_data, y_pred_full))

# Print RMSE values
print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE")
for size, rmse_fp, rmse_nr, rmse_lm in zip(sample_sizes, rmse_fixed_point, rmse_newton_raphson, rmse_levenberg_marquardt):
    print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm:.4f}")

# Plotting RMSE vs. Sample Size
plt.figure(figsize=(10, 6))
plt.plot(sample_sizes, rmse_fixed_point, label='Fixed-Point Iteration', marker='o')
plt.plot(sample_sizes, rmse_newton_raphson, label='Newton-Raphson', marker='o')
plt.plot(sample_sizes, rmse_levenberg_marquardt, label='Levenberg-Marquardt', marker='o')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.title('RMSE vs. Sample Size for Different Methods')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

def levenberg_marquardt(X, Y, max_iterations=1000, tolerance=1e-6, lambda_val=0.01):
    beta = np.zeros(X.shape[1])
    for i in range(max_iterations):
        Y_pred = X.dot(beta)
        error = Y_pred - Y
        gradient = np.mean(X * error[:, np.newaxis], axis=0)
        hessian = np.mean(X**2, axis=0)
        if np.abs(gradient).max() < tolerance:
            break
        beta = beta - gradient / (hessian + lambda_val)
    return beta, i + 1  # return beta and number of iterations

def collect_and_plot_lambda(X, Y, lambda_values):
    rmse = []
    iterations = []

    for lambda_val in lambda_values:
        beta_lm, iter_count = levenberg_marquardt(X, Y, lambda_val=lambda_val)
        Y_pred = X.dot(beta_lm)
        rmse_val = np.sqrt(np.mean((Y_pred - Y)**2))
        rmse.append(rmse_val)
        iterations.append(iter_count)

    # Print results
    print(f"Lambda Values: {lambda_values}")
    print(f"RMSE: {rmse}")
    print(f"Iterations: {iterations}")

    # Plotting RMSE and Iterations
    fig, ax1 = plt.subplots()

    color = 'tab:red'
    ax1.set_xlabel('Lambda Values')
    ax1.set_ylabel('RMSE', color=color)
    ax1.plot(lambda_values, rmse, marker='o', color=color)
    ax1.tick_params(axis='y', labelcolor=color)

    ax2 = ax1.twinx()
    color = 'tab:blue'
    ax2.set_ylabel('Iterations', color=color)
    ax2.plot(lambda_values, iterations, marker='x', color=color)
    ax2.tick_params(axis='y', labelcolor=color)

    fig.tight_layout()
    plt.title('Levenberg-Marquardt: RMSE and Iterations vs Lambda')
    plt.grid(True)
    plt.show()

# Example usage with simulated data
np.random.seed(0)
n_samples = 1000
n_features = 3
X = np.random.randn(n_samples, n_features)
true_beta = np.array([2.5, -1.0, 0.5])
Y = X.dot(true_beta) + np.random.normal(0, 1, n_samples)

# Lambda values to test
lambda_values = [0.01, 0.1, 1, 10, 100]

# Collect and plot results
collect_and_plot_lambda(X, Y, lambda_values)

import numpy as np
import matplotlib.pyplot as plt

# Simulate data with different population characteristics
def simulate_data(x, true_params, noise_std):
    return true_params[0] * np.sin(true_params[1] * x) + true_params[2] + np.random.normal(0, noise_std, len(x))

# Function to compute RMSE
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

# Function to generate different sample sizes
def generate_sample_sizes(x, y, sizes):
    sample_data = []
    for size in sizes:
        indices = np.random.choice(len(x), size, replace=False)
        sample_data.append((x[indices], y[indices]))
    return sample_data

# Parameters for simulation
np.random.seed(42)
true_params = np.array([1.5, -2.0, 1.0])
x_data = np.linspace(0, 10, 100)
noise_std = 0.5

# Generate data for base scenario
y_data_base = simulate_data(x_data, true_params, noise_std)

# Different population characteristics
population_params = [
    np.array([1.2, -2.0, 1.0]),  # Different amplitude
    np.array([1.5, -1.5, 1.0]),  # Different frequency
    np.array([1.5, -2.0, 0.5])   # Different mean
]
population_labels = ['Different Amplitude', 'Different Frequency', 'Different Mean']

# Sample sizes to test
sample_sizes = np.arange(10, 101, 10)

# Placeholder for RMSE values
rmse_methods = {
    'Fixed-Point Iteration': [],
    'Newton-Raphson': [],
    'Levenberg-Marquardt': []
}

# Initial parameter guess
initial_params = np.array([1.0, -1.0, 0.5])

# Function to evaluate methods with different data
def evaluate_methods(sample_data, initial_params):
    rmse_values = {method: [] for method in rmse_methods}

    for x_sample, y_sample in sample_data:
        # Fixed-Point Iteration
        params_fp = initial_params.copy()
        for i in range(100):
            y_pred_fp = params_fp[0] * np.sin(params_fp[1] * x_sample) + params_fp[2]
            error_fp = y_sample - y_pred_fp
            params_fp += 0.01 * np.array([
                np.sum(error_fp * np.sin(params_fp[1] * x_sample)),
                np.sum(error_fp * params_fp[0] * x_sample * np.cos(params_fp[1] * x_sample)),
                np.sum(error_fp)
            ])
        y_pred_full_fp = params_fp[0] * np.sin(params_fp[1] * x_data) + params_fp[2]
        rmse_values['Fixed-Point Iteration'].append(rmse(y_data_base, y_pred_full_fp))

        # Newton-Raphson
        params_nr = initial_params.copy()
        for i in range(10):
            y_pred_nr = params_nr[0] * np.sin(params_nr[1] * x_sample) + params_nr[2]
            error_nr = y_sample - y_pred_nr
            J_nr = np.vstack((
                np.sin(params_nr[1] * x_sample),
                params_nr[0] * x_sample * np.cos(params_nr[1] * x_sample),
                np.ones_like(x_sample)
            )).T
            H_nr = J_nr.T @ J_nr
            params_nr += np.linalg.inv(H_nr) @ J_nr.T @ error_nr
        y_pred_full_nr = params_nr[0] * np.sin(params_nr[1] * x_data) + params_nr[2]
        rmse_values['Newton-Raphson'].append(rmse(y_data_base, y_pred_full_nr))

        # Levenberg-Marquardt
        params_lm = initial_params.copy()
        lambda_param = 0.01
        for i in range(10):
            y_pred_lm = params_lm[0] * np.sin(params_lm[1] * x_sample) + params_lm[2]
            error_lm = y_sample - y_pred_lm
            J_lm = np.vstack((
                np.sin(params_lm[1] * x_sample),
                params_lm[0] * x_sample * np.cos(params_lm[1] * x_sample),
                np.ones_like(x_sample)
            )).T
            H_lm = J_lm.T @ J_lm
            params_lm += np.linalg.inv(H_lm + lambda_param * np.eye(3)) @ J_lm.T @ error_lm
        y_pred_full_lm = params_lm[0] * np.sin(params_lm[1] * x_data) + params_lm[2]
        rmse_values['Levenberg-Marquardt'].append(rmse(y_data_base, y_pred_full_lm))

    return rmse_values

# Evaluate methods for base scenario
rmse_methods_base = evaluate_methods(generate_sample_sizes(x_data, y_data_base, sample_sizes), initial_params)

# Evaluate methods for different population characteristics
rmse_methods_characteristics = []
for params in population_params:
    y_data_characteristic = simulate_data(x_data, params, noise_std)
    rmse_characteristic = evaluate_methods(generate_sample_sizes(x_data, y_data_characteristic, sample_sizes), initial_params)
    rmse_methods_characteristics.append(rmse_characteristic)

# Print and plot results for base scenario
print("Base Scenario: Evaluate Three Non-linear Iterative Estimation Techniques")
print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE")
for size, rmse_fp, rmse_nr, rmse_lm in zip(sample_sizes, rmse_methods_base['Fixed-Point Iteration'], rmse_methods_base['Newton-Raphson'], rmse_methods_base['Levenberg-Marquardt']):
    print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm:.4f}")

# Plot RMSE vs. Sample Size for base scenario
plt.figure(figsize=(10, 6))
plt.plot(sample_sizes, rmse_methods_base['Fixed-Point Iteration'], label='Fixed-Point Iteration', marker='o')
plt.plot(sample_sizes, rmse_methods_base['Newton-Raphson'], label='Newton-Raphson', marker='o')
plt.plot(sample_sizes, rmse_methods_base['Levenberg-Marquardt'], label='Levenberg-Marquardt', marker='o')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.title('Base Scenario: RMSE vs. Sample Size for Different Methods')
plt.legend()
plt.grid(True)
plt.show()

# Print and plot results for different population characteristics
for i, (params, label) in enumerate(zip(population_params, population_labels)):
    print(f"\nPopulation Characteristic: {label}")
    print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE")
    for size, rmse_fp, rmse_nr, rmse_lm in zip(sample_sizes, rmse_methods_characteristics[i]['Fixed-Point Iteration'], rmse_methods_characteristics[i]['Newton-Raphson'], rmse_methods_characteristics[i]['Levenberg-Marquardt']):
        print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm:.4f}")

    # Plot RMSE vs. Sample Size for different population characteristics
    plt.figure(figsize=(10, 6))
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Fixed-Point Iteration'], label='Fixed-Point Iteration', marker='o')
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Newton-Raphson'], label='Newton-Raphson', marker='o')
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Levenberg-Marquardt'], label='Levenberg-Marquardt', marker='o')
    plt.xlabel('Sample Size')
    plt.ylabel('RMSE')
    plt.title(f"{label}: RMSE vs. Sample Size for Different Methods")
    plt.legend()
    plt.grid(True)
    plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Simulate data with different population characteristics
def simulate_data(x, true_params, noise_std):
    return true_params[0] * np.sin(true_params[1] * x) + true_params[2] + np.random.normal(0, noise_std, len(x))

# Function to compute RMSE
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

# Function to generate different sample sizes
def generate_sample_sizes(x, y, sizes):
    sample_data = []
    for size in sizes:
        indices = np.random.choice(len(x), size, replace=False)
        sample_data.append((x[indices], y[indices]))
    return sample_data

# Parameters for simulation
np.random.seed(42)
true_params = np.array([1.5, -2.0, 1.0])
x_data = np.linspace(0, 10, 100)
noise_std = 0.5

# Generate data for base scenario
y_data_base = simulate_data(x_data, true_params, noise_std)

# Different population characteristics
population_params = [
    np.array([1.5, -2.0, 1.0]),  # Base scenario (same as before)
    np.array([1.8, -2.0, 1.0]),  # Higher amplitude
    np.array([1.5, -1.8, 1.0]),  # Higher frequency
    np.array([1.5, -2.0, 0.8]),  # Lower mean
    np.array([1.5, -2.0, 1.2]),  # Higher mean
    np.array([1.5, -2.2, 1.0]),  # Shifted phase (different trend)
    np.array([1.3, -1.8, 1.0]),  # Lower amplitude, lower frequency
    np.array([1.8, -2.2, 1.2])   # Higher amplitude, shifted phase
]
population_labels = [
    'Base Scenario', 'Higher Amplitude', 'Higher Frequency',
    'Lower Mean', 'Higher Mean', 'Shifted Phase (Different Trend)',
    'Lower Amplitude, Lower Frequency', 'Higher Amplitude, Shifted Phase'
]

# Sample sizes to test
sample_sizes = np.arange(10, 101, 10)

# Placeholder for RMSE values
rmse_methods = {
    'Fixed-Point Iteration': [],
    'Newton-Raphson': [],
    'Levenberg-Marquardt': []
}

# Initial parameter guess
initial_params = np.array([1.0, -1.0, 0.5])

# Function to evaluate methods with different data
def evaluate_methods(sample_data, initial_params):
    rmse_values = {method: [] for method in rmse_methods}

    for x_sample, y_sample in sample_data:
        # Fixed-Point Iteration
        params_fp = initial_params.copy()
        for i in range(100):
            y_pred_fp = params_fp[0] * np.sin(params_fp[1] * x_sample) + params_fp[2]
            error_fp = y_sample - y_pred_fp
            params_fp += 0.01 * np.array([
                np.sum(error_fp * np.sin(params_fp[1] * x_sample)),
                np.sum(error_fp * params_fp[0] * x_sample * np.cos(params_fp[1] * x_sample)),
                np.sum(error_fp)
            ])
        y_pred_full_fp = params_fp[0] * np.sin(params_fp[1] * x_data) + params_fp[2]
        rmse_values['Fixed-Point Iteration'].append(rmse(y_data_base, y_pred_full_fp))

        # Newton-Raphson
        params_nr = initial_params.copy()
        for i in range(10):
            y_pred_nr = params_nr[0] * np.sin(params_nr[1] * x_sample) + params_nr[2]
            error_nr = y_sample - y_pred_nr
            J_nr = np.vstack((
                np.sin(params_nr[1] * x_sample),
                params_nr[0] * x_sample * np.cos(params_nr[1] * x_sample),
                np.ones_like(x_sample)
            )).T
            H_nr = J_nr.T @ J_nr
            params_nr += np.linalg.inv(H_nr) @ J_nr.T @ error_nr
        y_pred_full_nr = params_nr[0] * np.sin(params_nr[1] * x_data) + params_nr[2]
        rmse_values['Newton-Raphson'].append(rmse(y_data_base, y_pred_full_nr))

        # Levenberg-Marquardt
        params_lm = initial_params.copy()
        lambda_param = 0.1
        for i in range(10):
            y_pred_lm = params_lm[0] * np.sin(params_lm[1] * x_sample) + params_lm[2]
            error_lm = y_sample - y_pred_lm
            J_lm = np.vstack((
                np.sin(params_lm[1] * x_sample),
                params_lm[0] * x_sample * np.cos(params_lm[1] * x_sample),
                np.ones_like(x_sample)
            )).T
            H_lm = J_lm.T @ J_lm
            params_lm += np.linalg.inv(H_lm + lambda_param * np.eye(3)) @ J_lm.T @ error_lm
        y_pred_full_lm = params_lm[0] * np.sin(params_lm[1] * x_data) + params_lm[2]
        rmse_values['Levenberg-Marquardt'].append(rmse(y_data_base, y_pred_full_lm))

    return rmse_values

# Evaluate methods for base scenario
rmse_methods_base = evaluate_methods(generate_sample_sizes(x_data, y_data_base, sample_sizes), initial_params)

# Evaluate methods for different population characteristics
rmse_methods_characteristics = []
for params in population_params:
    y_data_characteristic = simulate_data(x_data, params, noise_std)
    rmse_characteristic = evaluate_methods(generate_sample_sizes(x_data, y_data_characteristic, sample_sizes), initial_params)
    rmse_methods_characteristics.append(rmse_characteristic)

# Print and plot results for base scenario
print("Base Scenario: Evaluate Three Non-linear Iterative Estimation Techniques")
print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE")
for size, rmse_fp, rmse_nr, rmse_lm in zip(sample_sizes, rmse_methods_base['Fixed-Point Iteration'], rmse_methods_base['Newton-Raphson'], rmse_methods_base['Levenberg-Marquardt']):
    print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm:.4f}")

# Plot RMSE vs. Sample Size for base scenario
plt.figure(figsize=(10, 6))
plt.plot(sample_sizes, rmse_methods_base['Fixed-Point Iteration'], label='Fixed-Point Iteration', marker='o')
plt.plot(sample_sizes, rmse_methods_base['Newton-Raphson'], label='Newton-Raphson', marker='o')
plt.plot(sample_sizes, rmse_methods_base['Levenberg-Marquardt'], label='Levenberg-Marquardt', marker='o')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.title('Base Scenario: RMSE vs. Sample Size for Different Methods')
plt.legend()
plt.grid(True)
plt.show()

# Print and plot results for different population characteristics
for i, (params, label) in enumerate(zip(population_params, population_labels)):
    print(f"\nPopulation Characteristic: {label}")
    print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE")
    for size, rmse_fp, rmse_nr, rmse_lm in zip(sample_sizes, rmse_methods_characteristics[i]['Fixed-Point Iteration'], rmse_methods_characteristics[i]['Newton-Raphson'], rmse_methods_characteristics[i]['Levenberg-Marquardt']):
        print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm:.4f}")

    # Plot RMSE vs. Sample Size for different population characteristics
    plt.figure(figsize=(10, 6))
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Fixed-Point Iteration'], label='Fixed-Point Iteration', marker='o')
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Newton-Raphson'], label='Newton-Raphson', marker='o')
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Levenberg-Marquardt'], label='Levenberg-Marquardt', marker='o')
    plt.xlabel('Sample Size')
    plt.ylabel('RMSE')
    plt.title(f"{label}: RMSE vs. Sample Size for Different Methods")
    plt.legend()
    plt.grid(True)
    plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Simulate data
np.random.seed(42)
true_params = np.array([1.5, -2.0, 1.0])
x_data = np.linspace(0, 10, 100)
y_data = true_params[0] * np.sin(true_params[1] * x_data) + true_params[2] + np.random.normal(0, 0.5, len(x_data))

# Function to compute RMSE
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

# Function to generate different sample sizes
def generate_sample_sizes(x, y, sizes):
    sample_data = []
    for size in sizes:
        indices = np.random.choice(len(x), size, replace=False)
        sample_data.append((x[indices], y[indices]))
    return sample_data

# Sample sizes to test
sample_sizes = np.arange(10, 101, 10)

# Generate data for different sample sizes
sample_data = generate_sample_sizes(x_data, y_data, sample_sizes)

# Placeholder for RMSE values
rmse_fixed_point = []
rmse_newton_raphson = []
rmse_levenberg_marquardt = []

# Initial parameter guess
initial_params = np.array([1.0, -1.0, 0.5])

# Fixed-Point Iteration
for x_sample, y_sample in sample_data:
    params = initial_params.copy()
    for i in range(100):
        y_pred = params[0] * np.sin(params[1] * x_sample) + params[2]
        error = y_sample - y_pred
        params += 0.01 * np.array([np.sum(error * np.sin(params[1] * x_sample)),
                                   np.sum(error * params[0] * x_sample * np.cos(params[1] * x_sample)),
                                   np.sum(error)])
    y_pred_full = params[0] * np.sin(params[1] * x_data) + params[2]
    rmse_fixed_point.append(rmse(y_data, y_pred_full))

# Newton-Raphson
for x_sample, y_sample in sample_data:
    params = initial_params.copy()
    for i in range(10):
        y_pred = params[0] * np.sin(params[1] * x_sample) + params[2]
        error = y_sample - y_pred
        J = np.vstack((np.sin(params[1] * x_sample),
                       params[0] * x_sample * np.cos(params[1] * x_sample),
                       np.ones_like(x_sample))).T
        H = J.T @ J
        params += np.linalg.inv(H) @ J.T @ error
    y_pred_full = params[0] * np.sin(params[1] * x_data) + params[2]
    rmse_newton_raphson.append(rmse(y_data, y_pred_full))

# Levenberg-Marquardt with Improved Initialization and Tuned Lambda
rmse_levenberg_marquardt_improved = []

# Improved Initial Parameter Guess
initial_params_lm = np.array([1.5, -2.0, 1.0])

# Tuned Lambda Parameter
lambda_param = 0.1

for x_sample, y_sample in sample_data:
    params = initial_params_lm.copy()
    for i in range(10):
        y_pred = params[0] * np.sin(params[1] * x_sample) + params[2]
        error = y_sample - y_pred
        J = np.vstack((np.sin(params[1] * x_sample),
                       params[0] * x_sample * np.cos(params[1] * x_sample),
                       np.ones_like(x_sample))).T
        H = J.T @ J
        params += np.linalg.inv(H + lambda_param * np.eye(3)) @ J.T @ error
    y_pred_full = params[0] * np.sin(params[1] * x_data) + params[2]
    rmse_levenberg_marquardt_improved.append(rmse(y_data, y_pred_full))

# Print RMSE values
print("Objective 1: Evaluate Three Non-linear Iterative Estimation Techniques")
print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE (Improved)")
for size, rmse_fp, rmse_nr, rmse_lm_improved in zip(sample_sizes, rmse_fixed_point, rmse_newton_raphson, rmse_levenberg_marquardt_improved):
    print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm_improved:.4f}")

# Plotting RMSE vs. Sample Size
plt.figure(figsize=(10, 6))
plt.plot(sample_sizes, rmse_fixed_point, label='Fixed-Point Iteration', marker='o')
plt.plot(sample_sizes, rmse_newton_raphson, label='Newton-Raphson', marker='o')
plt.plot(sample_sizes, rmse_levenberg_marquardt_improved, label='Levenberg-Marquardt (Improved)', marker='o')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.title('Objective 1: RMSE vs. Sample Size for Different Methods')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Function to generate data with population characteristics
def generate_population_data(x, true_params, noise_std):
    return true_params[0] * np.sin(true_params[1] * x) + true_params[2] + np.random.normal(0, noise_std, len(x))

# Function to compute RMSE
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

# Function to generate different sample sizes
def generate_sample_sizes(x, y, sizes):
    sample_data = []
    for size in sizes:
        indices = np.random.choice(len(x), size, replace=False)
        sample_data.append((x[indices], y[indices]))
    return sample_data

# Simulate data with specific population characteristics
np.random.seed(42)
true_params = np.array([1.5, -2.0, 1.0])
x_data = np.linspace(0, 10, 100)
population_noise_std = 0.5  # Population noise standard deviation

y_data_population = generate_population_data(x_data, true_params, population_noise_std)

# Sample sizes to test
sample_sizes = np.arange(10, 101, 10)

# Generate data for different sample sizes
sample_data = generate_sample_sizes(x_data, y_data_population, sample_sizes)

# Placeholder for RMSE values
rmse_fixed_point = []
rmse_newton_raphson = []
rmse_levenberg_marquardt = []

# Initial parameter guess
initial_params = np.array([1.0, -1.0, 0.5])

# Fixed-Point Iteration
for x_sample, y_sample in sample_data:
    params = initial_params.copy()
    for i in range(100):
        y_pred = params[0] * np.sin(params[1] * x_sample) + params[2]
        error = y_sample - y_pred
        params += 0.01 * np.array([np.sum(error * np.sin(params[1] * x_sample)),
                                   np.sum(error * params[0] * x_sample * np.cos(params[1] * x_sample)),
                                   np.sum(error)])
    y_pred_full = params[0] * np.sin(params[1] * x_data) + params[2]
    rmse_fixed_point.append(rmse(y_data_population, y_pred_full))

# Newton-Raphson
for x_sample, y_sample in sample_data:
    params = initial_params.copy()
    for i in range(10):
        y_pred = params[0] * np.sin(params[1] * x_sample) + params[2]
        error = y_sample - y_pred
        J = np.vstack((np.sin(params[1] * x_sample),
                       params[0] * x_sample * np.cos(params[1] * x_sample),
                       np.ones_like(x_sample))).T
        H = J.T @ J
        params += np.linalg.inv(H) @ J.T @ error
    y_pred_full = params[0] * np.sin(params[1] * x_data) + params[2]
    rmse_newton_raphson.append(rmse(y_data_population, y_pred_full))

# Levenberg-Marquardt with Improved Initialization and Tuned Lambda
rmse_levenberg_marquardt_improved = []

# Improved Initial Parameter Guess
initial_params_lm = np.array([1.5, -2.0, 1.0])

# Tuned Lambda Parameter
lambda_param = 0.1

for x_sample, y_sample in sample_data:
    params = initial_params_lm.copy()
    for i in range(10):
        y_pred = params[0] * np.sin(params[1] * x_sample) + params[2]
        error = y_sample - y_pred
        J = np.vstack((np.sin(params[1] * x_sample),
                       params[0] * x_sample * np.cos(params[1] * x_sample),
                       np.ones_like(x_sample))).T
        H = J.T @ J
        params += np.linalg.inv(H + lambda_param * np.eye(3)) @ J.T @ error
    y_pred_full = params[0] * np.sin(params[1] * x_data) + params[2]
    rmse_levenberg_marquardt_improved.append(rmse(y_data_population, y_pred_full))

# Print RMSE values
print("Objective 1: Evaluate Three Non-linear Iterative Estimation Techniques with Population Characteristics")
print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE (Improved)")
for size, rmse_fp, rmse_nr, rmse_lm_improved in zip(sample_sizes, rmse_fixed_point, rmse_newton_raphson, rmse_levenberg_marquardt_improved):
    print(f"{size}\t\t{rmse_fp:.4f}\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm_improved:.4f}")

# Plotting RMSE vs. Sample Size
plt.figure(figsize=(10, 6))
plt.plot(sample_sizes, rmse_fixed_point, label='Fixed-Point Iteration', marker='o')
plt.plot(sample_sizes, rmse_newton_raphson, label='Newton-Raphson', marker='o')
plt.plot(sample_sizes, rmse_levenberg_marquardt_improved, label='Levenberg-Marquardt (Improved)', marker='o')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.title('Objective 1: RMSE vs. Sample Size for Different Methods with Population Characteristics')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Simulate data with different population characteristics
def simulate_data(x, true_params, noise_std):
    return true_params[0] * np.sin(true_params[1] * x) + true_params[2] + np.random.normal(0, noise_std, len(x))

# Function to compute RMSE
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

# Function to generate different sample sizes
def generate_sample_sizes(x, y, sizes):
    sample_data = []
    for size in sizes:
        indices = np.random.choice(len(x), size, replace=False)
        sample_data.append((x[indices], y[indices]))
    return sample_data

# Parameters for simulation
np.random.seed(42)
true_params = np.array([1.5, -2.0, 1.0])
x_data = np.linspace(0, 10, 100)
noise_std = 0.5

# Generate data for base scenario
y_data_base = simulate_data(x_data, true_params, noise_std)

# Different population characteristics
population_params = [
    np.array([1.5, -2.0, 1.0]),  # Base scenario (same as before)
    np.array([1.8, -2.0, 1.0]),  # Higher amplitude
    np.array([1.5, -1.8, 1.0]),  # Higher frequency
    np.array([1.5, -2.0, 0.8]),  # Lower mean
    np.array([1.5, -2.0, 1.2]),  # Higher mean
    np.array([1.5, -2.2, 1.0]),  # Shifted phase (different trend)
    np.array([1.3, -1.8, 1.0]),  # Lower amplitude, lower frequency
    np.array([1.8, -2.2, 1.2])   # Higher amplitude, shifted phase
]
population_labels = [
    'Base Scenario', 'Higher Amplitude', 'Higher Frequency',
    'Lower Mean', 'Higher Mean', 'Shifted Phase (Different Trend)',
    'Lower Amplitude, Lower Frequency', 'Higher Amplitude, Shifted Phase'
]

# Sample sizes to test
sample_sizes = np.arange(10, 101, 10)

# Placeholder for RMSE values
rmse_methods = {
    'Fixed-Point Iteration': [],
    'Newton-Raphson': [],
    'Levenberg-Marquardt': []
}

# Initial parameter guess
initial_params = np.array([1.0, -1.0, 0.5])

# Function to evaluate methods with different data
def evaluate_methods(sample_data, initial_params):
    rmse_values = {method: [] for method in rmse_methods}

    for x_sample, y_sample in sample_data:
        # Fixed-Point Iteration
        params_fp = initial_params.copy()
        for i in range(100):
            y_pred_fp = params_fp[0] * np.sin(params_fp[1] * x_sample) + params_fp[2]
            error_fp = y_sample - y_pred_fp
            params_fp += 0.01 * np.array([
                np.sum(error_fp * np.sin(params_fp[1] * x_sample)),
                np.sum(error_fp * params_fp[0] * x_sample * np.cos(params_fp[1] * x_sample)),
                np.sum(error_fp)
            ])
        y_pred_full_fp = params_fp[0] * np.sin(params_fp[1] * x_data) + params_fp[2]
        rmse_values['Fixed-Point Iteration'].append(rmse(y_data_base, y_pred_full_fp))

        # Newton-Raphson
        params_nr = initial_params.copy()
        for i in range(10):
            y_pred_nr = params_nr[0] * np.sin(params_nr[1] * x_sample) + params_nr[2]
            error_nr = y_sample - y_pred_nr
            J_nr = np.vstack((
                np.sin(params_nr[1] * x_sample),
                params_nr[0] * x_sample * np.cos(params_nr[1] * x_sample),
                np.ones_like(x_sample)
            )).T
            H_nr = J_nr.T @ J_nr
            params_nr += np.linalg.inv(H_nr) @ J_nr.T @ error_nr
        y_pred_full_nr = params_nr[0] * np.sin(params_nr[1] * x_data) + params_nr[2]
        rmse_values['Newton-Raphson'].append(rmse(y_data_base, y_pred_full_nr))

        # Levenberg-Marquardt
        params_lm = initial_params.copy()
        lambda_param = 0.1
        for i in range(10):
            y_pred_lm = params_lm[0] * np.sin(params_lm[1] * x_sample) + params_lm[2]
            error_lm = y_sample - y_pred_lm
            J_lm = np.vstack((
                np.sin(params_lm[1] * x_sample),
                params_lm[0] * x_sample * np.cos(params_lm[1] * x_sample),
                np.ones_like(x_sample)
            )).T
            H_lm = J_lm.T @ J_lm
            params_lm += np.linalg.inv(H_lm + lambda_param * np.eye(3)) @ J_lm.T @ error_lm
        y_pred_full_lm = params_lm[0] * np.sin(params_lm[1] * x_data) + params_lm[2]
        rmse_values['Levenberg-Marquardt'].append(rmse(y_data_base, y_pred_full_lm))

    return rmse_values

# Evaluate methods for base scenario
rmse_methods_base = evaluate_methods(generate_sample_sizes(x_data, y_data_base, sample_sizes), initial_params)

# Evaluate methods for different population characteristics
rmse_methods_characteristics = []
for params in population_params:
    y_data_characteristic = simulate_data(x_data, params, noise_std)
    rmse_characteristic = evaluate_methods(generate_sample_sizes(x_data, y_data_characteristic, sample_sizes), initial_params)
    rmse_methods_characteristics.append(rmse_characteristic)

# Print and plot results for base scenario
print("Base Scenario: Evaluate Three Non-linear Iterative Estimation Techniques")
print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE")
for size, rmse_fp, rmse_nr, rmse_lm in zip(sample_sizes, rmse_methods_base['Fixed-Point Iteration'], rmse_methods_base['Newton-Raphson'], rmse_methods_base['Levenberg-Marquardt']):
    print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm:.4f}")

# Plot RMSE vs. Sample Size for base scenario
plt.figure(figsize=(10, 6))
plt.plot(sample_sizes, rmse_methods_base['Fixed-Point Iteration'], label='Fixed-Point Iteration', marker='o')
plt.plot(sample_sizes, rmse_methods_base['Newton-Raphson'], label='Newton-Raphson', marker='o')
plt.plot(sample_sizes, rmse_methods_base['Levenberg-Marquardt'], label='Levenberg-Marquardt', marker='o')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.title('Base Scenario: RMSE vs. Sample Size for Different Methods')
plt.legend()
plt.grid(True)
plt.show()

# Print and plot results for different population characteristics
for i, (params, label) in enumerate(zip(population_params, population_labels)):
    print(f"\nPopulation Characteristic: {label}")
    print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE")
    for size, rmse_fp, rmse_nr, rmse_lm in zip(sample_sizes, rmse_methods_characteristics[i]['Fixed-Point Iteration'], rmse_methods_characteristics[i]['Newton-Raphson'], rmse_methods_characteristics[i]['Levenberg-Marquardt']):
        print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm:.4f}")

    # Plot RMSE vs. Sample Size for different population characteristics
    plt.figure(figsize=(10, 6))
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Fixed-Point Iteration'], label='Fixed-Point Iteration', marker='o')
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Newton-Raphson'], label='Newton-Raphson', marker='o')
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Levenberg-Marquardt'], label='Levenberg-Marquardt', marker='o')
    plt.xlabel('Sample Size')
    plt.ylabel('RMSE')
    plt.title(f"{label}: RMSE vs. Sample Size for Different Methods")
    plt.legend()
    plt.grid(True)
    plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Simulate data with different population characteristics
def simulate_data(x, true_params, noise_std):
    return true_params[0] * np.sin(true_params[1] * x) + true_params[2] + np.random.normal(0, noise_std, len(x))

# Function to compute RMSE
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

# Function to generate different sample sizes
def generate_sample_sizes(x, y, sizes):
    sample_data = []
    for size in sizes:
        indices = np.random.choice(len(x), size, replace=False)
        sample_data.append((x[indices], y[indices]))
    return sample_data

# Parameters for simulation
np.random.seed(42)
true_params = np.array([1.5, -2.0, 1.0])
x_data = np.linspace(0, 10, 100)
noise_std = 0.5

# Generate data for base scenario
y_data_base = simulate_data(x_data, true_params, noise_std)

# Different population characteristics
population_params = [
    np.array([1.5, -2.0, 1.0]),  # Base scenario (same as before)
    np.array([1.8, -2.0, 1.0]),  # Higher amplitude
    np.array([1.5, -1.8, 1.0]),  # Higher frequency
    np.array([1.5, -2.0, 0.8]),  # Lower mean
    np.array([1.5, -2.0, 1.2]),  # Higher mean
    np.array([1.5, -2.2, 1.0]),  # Shifted phase (different trend)
    np.array([1.3, -1.8, 1.0]),  # Lower amplitude, lower frequency
    np.array([1.8, -2.2, 1.2])   # Higher amplitude, shifted phase
]
population_labels = [
    'Base Scenario', 'Higher Amplitude', 'Higher Frequency',
    'Lower Mean', 'Higher Mean', 'Shifted Phase (Different Trend)',
    'Lower Amplitude, Lower Frequency', 'Higher Amplitude, Shifted Phase'
]

# Sample sizes to test
sample_sizes = np.arange(10, 101, 10)

# Placeholder for RMSE values
rmse_methods = {
    'Fixed-Point Iteration': [],
    'Newton-Raphson': [],
    'Levenberg-Marquardt': [],
    'Levenberg-Marquardt Improved': []  # Added for the improved version
}

# Initial parameter guesses
initial_params = np.array([1.0, -1.0, 0.5])
initial_params_lm = np.array([1.5, -2.0, 1.0])  # Improved initial guess

# Function to evaluate methods with different data
def evaluate_methods(sample_data, initial_params, initial_params_lm):
    rmse_values = {method: [] for method in rmse_methods}

    for x_sample, y_sample in sample_data:
        # Fixed-Point Iteration
        params_fp = initial_params.copy()
        for i in range(100):
            y_pred_fp = params_fp[0] * np.sin(params_fp[1] * x_sample) + params_fp[2]
            error_fp = y_sample - y_pred_fp
            params_fp += 0.01 * np.array([
                np.sum(error_fp * np.sin(params_fp[1] * x_sample)),
                np.sum(error_fp * params_fp[0] * x_sample * np.cos(params_fp[1] * x_sample)),
                np.sum(error_fp)
            ])
        y_pred_full_fp = params_fp[0] * np.sin(params_fp[1] * x_data) + params_fp[2]
        rmse_values['Fixed-Point Iteration'].append(rmse(y_data_base, y_pred_full_fp))

        # Newton-Raphson
        params_nr = initial_params.copy()
        for i in range(10):
            y_pred_nr = params_nr[0] * np.sin(params_nr[1] * x_sample) + params_nr[2]
            error_nr = y_sample - y_pred_nr
            J_nr = np.vstack((
                np.sin(params_nr[1] * x_sample),
                params_nr[0] * x_sample * np.cos(params_nr[1] * x_sample),
                np.ones_like(x_sample)
            )).T
            H_nr = J_nr.T @ J_nr
            params_nr += np.linalg.inv(H_nr) @ J_nr.T @ error_nr
        y_pred_full_nr = params_nr[0] * np.sin(params_nr[1] * x_data) + params_nr[2]
        rmse_values['Newton-Raphson'].append(rmse(y_data_base, y_pred_full_nr))

        # Levenberg-Marquardt
        params_lm = initial_params.copy()
        lambda_param = 0.1
        for i in range(10):
            y_pred_lm = params_lm[0] * np.sin(params_lm[1] * x_sample) + params_lm[2]
            error_lm = y_sample - y_pred_lm
            J_lm = np.vstack((
                np.sin(params_lm[1] * x_sample),
                params_lm[0] * x_sample * np.cos(params_lm[1] * x_sample),
                np.ones_like(x_sample)
            )).T
            H_lm = J_lm.T @ J_lm
            params_lm += np.linalg.inv(H_lm + lambda_param * np.eye(3)) @ J_lm.T @ error_lm
        y_pred_full_lm = params_lm[0] * np.sin(params_lm[1] * x_data) + params_lm[2]
        rmse_values['Levenberg-Marquardt'].append(rmse(y_data_base, y_pred_full_lm))

        # Levenberg-Marquardt Improved
        params_lm_improved = initial_params_lm.copy()
        lambda_param_improved = 0.1
        for i in range(10):
            y_pred_lm_improved = params_lm_improved[0] * np.sin(params_lm_improved[1] * x_sample) + params_lm_improved[2]
            error_lm_improved = y_sample - y_pred_lm_improved
            J_lm_improved = np.vstack((
                np.sin(params_lm_improved[1] * x_sample),
                params_lm_improved[0] * x_sample * np.cos(params_lm_improved[1] * x_sample),
                np.ones_like(x_sample)
            )).T
            H_lm_improved = J_lm_improved.T @ J_lm_improved
            params_lm_improved += np.linalg.inv(H_lm_improved + lambda_param_improved * np.eye(3)) @ J_lm_improved.T @ error_lm_improved
        y_pred_full_lm_improved = params_lm_improved[0] * np.sin(params_lm_improved[1] * x_data) + params_lm_improved[2]
        rmse_values['Levenberg-Marquardt Improved'].append(rmse(y_data_base, y_pred_full_lm_improved))

    return rmse_values

# Evaluate methods for base scenario
rmse_methods_base = evaluate_methods(generate_sample_sizes(x_data, y_data_base, sample_sizes), initial_params, initial_params_lm)

# Evaluate methods for different population characteristics
rmse_methods_characteristics = []
for params in population_params:
    y_data_characteristic = simulate_data(x_data, params, noise_std)
    rmse_characteristic = evaluate_methods(generate_sample_sizes(x_data, y_data_characteristic, sample_sizes), initial_params, initial_params_lm)
    rmse_methods_characteristics.append(rmse_characteristic)

# Print and plot results for base scenario
print("\nBase Scenario: Evaluate Three Non-linear Iterative Estimation Techniques")
print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE\tLevenberg-Marquardt Improved RMSE")
for size, rmse_fp, rmse_nr, rmse_lm, rmse_lm_improved in zip(sample_sizes, rmse_methods_base['Fixed-Point Iteration'], rmse_methods_base['Newton-Raphson'], rmse_methods_base['Levenberg-Marquardt'], rmse_methods_base['Levenberg-Marquardt Improved']):
    print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm:.4f}\t\t\t{rmse_lm_improved:.4f}")

# Plot RMSE vs. Sample Size for base scenario
plt.figure(figsize=(10, 6))
plt.plot(sample_sizes, rmse_methods_base['Fixed-Point Iteration'], label='Fixed-Point Iteration', marker='o')
plt.plot(sample_sizes, rmse_methods_base['Newton-Raphson'], label='Newton-Raphson', marker='o')
plt.plot(sample_sizes, rmse_methods_base['Levenberg-Marquardt'], label='Levenberg-Marquardt', marker='o')
plt.plot(sample_sizes, rmse_methods_base['Levenberg-Marquardt Improved'], label='Levenberg-Marquardt Improved', marker='o')
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.title('Base Scenario: RMSE vs. Sample Size for Different Methods')
plt.legend()
plt.grid(True)
plt.show()

# Print and plot results for different population characteristics
for i, (params, label) in enumerate(zip(population_params, population_labels)):
    print(f"\nPopulation Characteristic: {label}")
    print("Sample Size\tFixed-Point Iteration RMSE\tNewton-Raphson RMSE\tLevenberg-Marquardt RMSE\tLevenberg-Marquardt Improved RMSE")
    for size, rmse_fp, rmse_nr, rmse_lm, rmse_lm_improved in zip(sample_sizes, rmse_methods_characteristics[i]['Fixed-Point Iteration'], rmse_methods_characteristics[i]['Newton-Raphson'], rmse_methods_characteristics[i]['Levenberg-Marquardt'], rmse_methods_characteristics[i]['Levenberg-Marquardt Improved']):
        print(f"{size}\t\t{rmse_fp:.4f}\t\t\t\t{rmse_nr:.4f}\t\t\t{rmse_lm:.4f}\t\t\t{rmse_lm_improved:.4f}")

    # Plot RMSE vs. Sample Size for different population characteristics
    plt.figure(figsize=(10, 6))
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Fixed-Point Iteration'], label='Fixed-Point Iteration', marker='o')
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Newton-Raphson'], label='Newton-Raphson', marker='o')
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Levenberg-Marquardt'], label='Levenberg-Marquardt', marker='o')
    plt.plot(sample_sizes, rmse_methods_characteristics[i]['Levenberg-Marquardt Improved'], label='Levenberg-Marquardt Improved', marker='o')
    plt.xlabel('Sample Size')
    plt.ylabel('RMSE')
    plt.title(f"{label}: RMSE vs. Sample Size for Different Methods")
    plt.legend()
    plt.grid(True)
    plt.show()

import numpy as np
import matplotlib.pyplot as plt

# Simulate data with different population characteristics
def simulate_data(x, true_params, noise_std):
    return true_params[0] * np.sin(true_params[1] * x) + true_params[2] + np.random.normal(0, noise_std, len(x))

# Function to compute RMSE
def rmse(y_true, y_pred):
    return np.sqrt(np.mean((y_true - y_pred) ** 2))

# Function to generate different sample sizes
def generate_sample_sizes(x, y, sizes):
    sample_data = []
    for size in sizes:
        indices = np.random.choice(len(x), size, replace=False)
        sample_data.append((x[indices], y[indices]))
    return sample_data

# Parameters for simulation
np.random.seed(42)
true_params = np.array([1.5, -2.0, 1.0])
x_data = np.linspace(0, 10, 100)
noise_std = 0.5

# Generate data for base scenario
y_data_base = simulate_data(x_data, true_params, noise_std)

# Improved Initial Parameter Guess
initial_params_lm = np.array([1.5, -2.0, 1.0])

# Convergence criteria to test
convergence_criteria = [1e-4, 1e-5, 1e-6, 1e-7]

# Sample sizes to test
sample_sizes = np.arange(10, 101, 10)

# Placeholder for results
results = []

# Evaluate the algorithm for each convergence criterion
for criterion in convergence_criteria:
    rmse_values = []
    iterations = []
    for size in sample_sizes:
        sample_data = generate_sample_sizes(x_data, y_data_base, [size])[0]

        params_lm = initial_params_lm.copy()
        iter_count = 0
        while True:
            y_pred_lm = params_lm[0] * np.sin(params_lm[1] * sample_data[0]) + params_lm[2]
            error_lm = sample_data[1] - y_pred_lm
            J_lm = np.vstack((
                np.sin(params_lm[1] * sample_data[0]),
                params_lm[0] * sample_data[0] * np.cos(params_lm[1] * sample_data[0]),
                np.ones_like(sample_data[0])
            )).T
            H_lm = J_lm.T @ J_lm
            params_lm_new = params_lm + np.linalg.inv(H_lm + criterion * np.eye(3)) @ J_lm.T @ error_lm
            iter_count += 1
            if np.allclose(params_lm, params_lm_new, rtol=1e-6):
                break
            params_lm = params_lm_new

        y_pred_full_lm = params_lm[0] * np.sin(params_lm[1] * x_data) + params_lm[2]
        rmse_value = rmse(y_data_base, y_pred_full_lm)

        rmse_values.append(rmse_value)
        iterations.append(iter_count)

    results.append({
        'criterion': criterion,
        'sample_sizes': sample_sizes,
        'iterations': iterations,
        'rmse_values': rmse_values
    })

# Print the results
for result in results:
    print(f"\nConvergence Criterion: {result['criterion']}")
    print("Sample Size\tIterations\tRMSE")
    for size, iter_count, rmse_value in zip(result['sample_sizes'], result['iterations'], result['rmse_values']):
        print(f"{size}\t\t{iter_count}\t\t{rmse_value:.4f}")

# Plot iterations vs. sample size for each criterion
plt.figure(figsize=(10, 6))
for result in results:
    plt.plot(result['sample_sizes'], result['iterations'], label=f"Criterion: {result['criterion']}")
plt.xlabel('Sample Size')
plt.ylabel('Iterations')
plt.title('Iterations vs. Sample Size for Improved Levenberg-Marquardt')
plt.legend()
plt.grid(True)
plt.show()

# Plot RMSE vs. sample size for each criterion
plt.figure(figsize=(10, 6))
for result in results:
    plt.plot(result['sample_sizes'], result['rmse_values'], label=f"Criterion: {result['criterion']}")
plt.xlabel('Sample Size')
plt.ylabel('RMSE')
plt.title('RMSE vs. Sample Size for Improved Levenberg-Marquardt')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import matplotlib.pyplot as plt

def levenberg_marquardt_improved(X, Y, max_iterations=1000, tolerance=1e-6, lambda_val=0.1):
    beta = np.zeros(X.shape[1])
    for i in range(max_iterations):
        Y_pred = X.dot(beta)
        error = Y_pred - Y
        gradient = np.mean(X * error[:, np.newaxis], axis=0)
        hessian = np.mean(X**2, axis=0)
        if np.abs(gradient).max() < tolerance:
            break
        beta = beta - np.linalg.inv(np.diag(hessian) + lambda_val * np.eye(X.shape[1])) @ gradient
    return beta, i + 1  # return beta and number of iterations

def collect_and_plot_lambda_improved(X, Y, lambda_values):
    rmse = []
    iterations = []

    for lambda_val in lambda_values:
        beta_lm, iter_count = levenberg_marquardt_improved(X, Y, lambda_val=lambda_val)
        Y_pred = X.dot(beta_lm)
        rmse_val = np.sqrt(np.mean((Y_pred - Y)**2))
        rmse.append(rmse_val)
        iterations.append(iter_count)

    # Print results
    print(f"Lambda Values: {lambda_values}")
    print(f"RMSE: {rmse}")
    print(f"Iterations: {iterations}")

    # Plotting RMSE and Iterations
    fig, ax1 = plt.subplots()

    color = 'tab:red'
    ax1.set_xlabel('Lambda Values')
    ax1.set_ylabel('RMSE', color=color)
    ax1.plot(lambda_values, rmse, marker='o', color=color)
    ax1.tick_params(axis='y', labelcolor=color)

    ax2 = ax1.twinx()
    color = 'tab:blue'
    ax2.set_ylabel('Iterations', color=color)
    ax2.plot(lambda_values, iterations, marker='x', color=color)
    ax2.tick_params(axis='y', labelcolor=color)

    fig.tight_layout()
    plt.title('Improved Levenberg-Marquardt: RMSE and Iterations vs Lambda')
    plt.grid(True)
    plt.show()

# Example usage with simulated data
np.random.seed(0)
n_samples = 1000
n_features = 3
X = np.random.randn(n_samples, n_features)
true_beta = np.array([2.5, -1.0, 0.5])
Y = X.dot(true_beta) + np.random.normal(0, 1, n_samples)

# Lambda values to test
lambda_values = [0.01, 0.1, 1, 10, 100]

# Collect and plot results for improved Levenberg-Marquardt
collect_and_plot_lambda_improved(X, Y, lambda_values)

import numpy as np
import matplotlib.pyplot as plt

# Simulate data with different population characteristics
def simulate_data(x, true_params, noise_std):
    return true_params[0] * np.sin(true_params[1] * x) + true_params[2] + np.random.normal(0, noise_std, len(x))

# Function to calculate bias
def calculate_bias(beta_estimated, beta_true):
    return np.mean(beta_estimated - beta_true)

# Function to generate different sample sizes
def generate_sample_sizes(x, y, sizes):
    sample_data = []
    for size in sizes:
        indices = np.random.choice(len(x), size, replace=False)
        sample_data.append((x[indices], y[indices]))
    return sample_data

# Parameters for simulation
np.random.seed(42)
true_params = np.array([1.5, -2.0, 1.0])
x_data = np.linspace(0, 10, 100)
noise_std = 0.5

# Improved Initial Parameter Guess
initial_params_lm = np.array([1.5, -2.0, 1.0])

# Convergence criteria to test
convergence_criteria = [1e-4, 1e-5, 1e-6, 1e-7]

# Sample sizes to test
sample_sizes = np.arange(10, 101, 10)

# Placeholder for results
results = []

# Evaluate the algorithm for each convergence criterion
for criterion in convergence_criteria:
    biases = []
    for size in sample_sizes:
        sample_data = generate_sample_sizes(x_data, y_data_base, [size])[0]

        params_lm = initial_params_lm.copy()
        while True:
            y_pred_lm = params_lm[0] * np.sin(params_lm[1] * sample_data[0]) + params_lm[2]
            error_lm = sample_data[1] - y_pred_lm
            J_lm = np.vstack((
                np.sin(params_lm[1] * sample_data[0]),
                params_lm[0] * sample_data[0] * np.cos(params_lm[1] * sample_data[0]),
                np.ones_like(sample_data[0])
            )).T
            H_lm = J_lm.T @ J_lm
            params_lm_new = params_lm + np.linalg.inv(H_lm + criterion * np.eye(3)) @ J_lm.T @ error_lm
            if np.allclose(params_lm, params_lm_new, rtol=1e-6):
                break
            params_lm = params_lm_new

        bias_value = calculate_bias(params_lm, true_params)
        biases.append(bias_value)

    results.append({
        'criterion': criterion,
        'sample_sizes': sample_sizes,
        'biases': biases
    })

# Print the results
for result in results:
    print(f"\nConvergence Criterion: {result['criterion']}")
    print("Sample Size\tBias")
    for size, bias_value in zip(result['sample_sizes'], result['biases']):
        print(f"{size}\t\t{bias_value:.4f}")

# Plot Bias vs. sample size for each criterion
plt.figure(figsize=(10, 6))
for result in results:
    plt.plot(result['sample_sizes'], result['biases'], marker='o', label=f"Criterion: {result['criterion']}")
plt.xlabel('Sample Size')
plt.ylabel('Bias')
plt.title('Bias vs. Sample Size for Improved Levenberg-Marquardt')
plt.legend()
plt.grid(True)
plt.show()